# -*- coding: utf-8 -*-
"""LVADSUSR171_Nithikksha_Booking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s6GghyLxLfRTB52sFl0K1FdOoO3obofn
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder
le=LabelEncoder()
scaler = MinMaxScaler()
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

df=pd.read_csv("/content/booking.csv")
df.head()

df.shape

df.info()

df.describe(include="all")

df.columns

df.rename(columns={'number of adults':'number_of_adults'}, inplace=True)
df.rename(columns={'number of children':'number_of_children'}, inplace=True)
df.rename(columns={'number of weekend nights':'number_of_weekend_nights'}, inplace=True)
df.rename(columns={'type of meal':'type_of_meal'}, inplace=True)
df.rename(columns={'car parking space':'car_parking_space'}, inplace=True)
df.rename(columns={'room type':'room_type'}, inplace=True)
df.rename(columns={'market segment type':'market_segment_type'}, inplace=True)
df.rename(columns={'P-C':'P_C'}, inplace=True)
df.rename(columns={'P-not-C':'P_not_C'}, inplace=True)
df.rename(columns={'average price':'average_price'}, inplace=True)
df.rename(columns={'special requests':'special_requests'}, inplace=True)
df.rename(columns={'date of reservation':'date_of_reservation'}, inplace=True)
df.rename(columns={'booking status':'booking_status'}, inplace=True)

df.columns

df.isnull().sum()

df.duplicated().sum()

df.dtypes

"""**UNIVARIATE ANALYSIS**"""

for column in df.select_dtypes(include={'float64','int64'}).columns:
  plt.figure(figsize=(10,5))
  sns.histplot(df[column])
  plt.title(f'Histogram of {column}')
  plt.xlabel(column)
  plt.ylabel('Frequency')
  plt.show()

for column in df.select_dtypes(include={'float64','int64'}).columns:
  plt.figure(figsize=(10,5))
  sns.histplot(df[column])
  plt.title(f'Histogram of {column}')
  plt.xlabel(column)
  plt.ylabel('Frequency')
  plt.show()

"""**BIVARIATE ANALYSIS**"""

numerical_columns=df.select_dtypes(include={'float64','int64'}).columns
numerical_columns

for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
correlation_matrix = df[numerical_columns].corr()
print("Correlation matrix:\n", correlation_matrix)

plt.figure(figsize=(14, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

"""**NULL VALUE TREATMENT**"""

df.isnull().sum()

df.room_type.value_counts()

mode_value=df.room_type.mode()[0]
df.room_type=df.room_type.fillna(mode_value)

df.average_price=df.average_price.fillna(df.average_price.median())

df.isnull().sum()

df.duplicated().sum()

#Outlier boxplot
# Identify numerical columns by data type
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns

# Create a box plot for each numerical column
for column in numerical_columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

#Outlier detection
q1 = np.quantile(df["number_of_adults"] , 0.25)
q3 = np.quantile(df["number_of_adults"] , 0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
print("Q1:", q1)
print("Q3:", q3)
print("IQR:", iqr)
print("Lower Bound (Outlier):", lower_bound)
print("Upper Bound (Outlier):", upper_bound)
# Identify outliers
outliers = [i for i in df["number_of_adults"] if i < lower_bound or i > upper_bound]
print("Outliers:", outliers)

#Outlier detection
q1 = np.quantile(df["special_requests"] , 0.25)
q3 = np.quantile(df["special_requests"] , 0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
print("Q1:", q1)
print("Q3:", q3)
print("IQR:", iqr)
print("Lower Bound (Outlier):", lower_bound)
print("Upper Bound (Outlier):", upper_bound)
# Identify outliers
outliers = [i for i in df["special_requests"] if i < lower_bound or i > upper_bound]
print("Outliers:", outliers)

#Outlier detection
q1 = np.quantile(df["number_of_weekend_nights"] , 0.25)
q3 = np.quantile(df["number_of_weekend_nights"] , 0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
print("Q1:", q1)
print("Q3:", q3)
print("IQR:", iqr)
print("Lower Bound (Outlier):", lower_bound)
print("Upper Bound (Outlier):", upper_bound)
# Identify outliers
outliers = [i for i in df["number_of_weekend_nights"] if i < lower_bound or i > upper_bound]
print("Outliers:", outliers)

#Outlier detection
q1 = np.quantile(df["P_C"] , 0.25)
q3 = np.quantile(df["P_C"] , 0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
print("Q1:", q1)
print("Q3:", q3)
print("IQR:", iqr)
print("Lower Bound (Outlier):", lower_bound)
print("Upper Bound (Outlier):", upper_bound)
# Identify outliers
outliers = [i for i in df["P_C"] if i < lower_bound or i > upper_bound]
print("Outliers:", outliers)

#encoding data

df.dtypes

df.drop(columns=['Booking_ID'], inplace=True)

df.drop(columns=['date_of_reservation'], inplace=True)

df.type_of_meal=le.fit_transform(df.type_of_meal)
df.room_type=le.fit_transform(df.room_type)
df.market_segment_type=le.fit_transform(df.market_segment_type)
df.booking_status=le.fit_transform(df.booking_status)

df.dtypes

#train test split

x1 = df.drop(columns = ['booking_status'])
y1 = df[['booking_status']]

x1_train, x1_test, y1_train, y1_test=train_test_split(x1,y1,test_size=0.2)

#min max scaler
scaler=MinMaxScaler()
x1_train = scaler.fit_transform(x1_train)
x1_test = scaler.transform(x1_test)

#logistic regression model
model = LogisticRegression()
model.fit(x1_train, y1_train)
# Predictions
y1_pred = model.predict(x1_test)
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y1_test, y1_pred))
print("\nClassification Report:")
print(classification_report(y1_test, y1_pred))

# Accuracy
accuracy = accuracy_score(y1_test, y1_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y1_test, y1_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y1_test, y1_pred)
print("Recall:", recall)

# F1-score
f1_score = f1_score(y1_test, y1_pred)
print("F1-score:", f1_score)

