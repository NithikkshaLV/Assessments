# -*- coding: utf-8 -*-
"""LVADSUSR171_NITHIKKSHA_CLASSIFICATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oxpZGmcp51vKSm6mCRWqvDtZZYN7VE73
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.cluster.hierarchy import fcluster
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler,LabelEncoder
le=LabelEncoder()
from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,LabelEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, f1_score
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.ensemble import AdaBoostClassifier
from imblearn.over_sampling import SMOTE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv("/content/penguins_classification.csv")
df.head()

df.shape

df.info()

df.describe(include="all")

df.columns

df.isnull().sum()

df.duplicated().sum()

df.dtypes

df.head()

df.species.value_counts()

df.island.value_counts()

"""**UNIVARIATE ANALYSIS**"""

for column in df.select_dtypes(include={'float64','int64'}).columns:
  plt.figure(figsize=(10,5))
  sns.histplot(df[column])
  plt.title(f'Histogram of {column}')
  plt.xlabel(column)
  plt.ylabel('Frequency')
  plt.show()

"""**BIVARIATE ANALYSIS**"""

numerical_columns=df.select_dtypes(include={'float64','int64'}).columns
numerical_columns

for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

#correlation matrix
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
correlation_matrix = df[numerical_columns].corr()
print("Correlation matrix:\n", correlation_matrix)

plt.figure(figsize=(14, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

"""**NULL VALUE TREATMENT**"""

df.isnull().sum()

df.bill_depth_mm=df.bill_depth_mm.fillna(df.bill_depth_mm.median())

df.isnull().sum()

df.dtypes

df.duplicated().sum()

df.columns

#data type conversion-label encoder
df['island']=le.fit_transform(df['island'])
df['species']=le.fit_transform(df['species'])

df.dtypes

df.species.value_counts()

#Outlier boxplot
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for column in numerical_columns:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

#Outlier Identification
q1 = np.percentile(df['bill_length_mm'],25)
q3 = np.percentile(df['bill_length_mm'],75)
iqr = q3-q1

lower_bound = q1 - (1.5*iqr)
upper_bound = q3 + (1.5*iqr)
print(lower_bound)
print(upper_bound)

outliers_displacement = [i for i in df['bill_length_mm'] if i<lower_bound or i>upper_bound]
print("Outliers in bill_length_mm :",outliers_displacement)

"""**Class Imbalance**

**LOGISTIC REGRESSION**
"""

x = df.drop(columns = ['species'])
y = df[['species']]

x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2)

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)

#min max scaler
scaler=MinMaxScaler()
x_train_resampled = scaler.fit_transform(x_train_resampled)
x_test = scaler.transform(x_test)

#logistic regression model
model = LogisticRegression()
model.fit(x_train_resampled, y_train_resampled)
# Predictions
y_pred = model.predict(x_test)
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

# F1-score
f1_score = f1_score(y_test, y_pred)
print("F1-score:", f1_score)

"""**DECISION TREE**"""

#decision regression model
model = DecisionTreeClassifier()
model.fit(x_train_resampled, y_train_resampled)
# Predictions
y_pred = model.predict(x_test)
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

# F1-score
from sklearn.metrics import  f1_score
f1_score = f1_score(y_test, y_pred)
print("F1-score:", f1_score)

"""**RANDOM FOREST**"""

scaler=MinMaxScaler()
x_train=scaler.fit_transform(x_train_resampled)
x_test=scaler.transform(x_test)
model=RandomForestClassifier()
model.fit(x_train_resampled,y_train_resampled)
y_pred=model.predict(x_test)

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

#F1-score
from sklearn.metrics import f1_score
f1_score = f1_score(y_test, y_pred)
print("F1-score:", f1_score)

"""**KNN**"""

model =  KNeighborsClassifier(n_neighbors=2)
model.fit(x_train_resampled, y_train_resampled)
# Predictions
y_pred = model.predict(x_test)
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

# F1-score
from sklearn.metrics import f1_score
f1_score = f1_score(y_test, y_pred)
print("F1-score:", f1_score)

"""**SVM**"""

model =  SVC()
model.fit(x_train_resampled, y_train_resampled)
# Predictions
y_pred = model.predict(x_test)
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

# F1-score
from sklearn.metrics import f1_score
f1_score = f1_score(y_test, y_pred)
print("F1-score:", f1_score)

"""**XGBOOST**"""

model =  XGBClassifier()
model.fit(x_train_resampled, y_train_resampled)
# Predictions
y_pred = model.predict(x_test)
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

# F1-score
from sklearn.metrics import f1_score
f1_score = f1_score(y_test, y_pred)
print("F1-score:", f1_score)

"""**ADABOOST**"""

model =  AdaBoostClassifier()
model.fit(x_train_resampled, y_train_resampled)
# Predictions
y_pred = model.predict(x_test)
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred)
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred)
print("Recall:", recall)

# F1-score
from sklearn.metrics import f1_score
f1_score = f1_score(y_test, y_pred)
print("F1-score:", f1_score)

"""XG Boost classifier is the best fit model for the Penguin classification, the rest of the models are fully biased to 1 but XGBoost gives the best results with the high recall of 0.96, f1 score of 0.96 and high accuracy. but since the total number of rows in the dataset is low, the model is slightly overfitted."""







